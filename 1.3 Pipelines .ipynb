{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3: Pipelines\n",
    "================\n",
    "### Stringing it All Together\n",
    "_____________________\n",
    "\n",
    "**Pipelines** has a few different meanings in Data Science.\n",
    "\n",
    "This creates some ambiguity as the terms are often used interchangably.\n",
    "\n",
    "There's [Spark Pipelines](https://spark.apache.org/docs/2.2.0/ml-pipeline.html), used to process data in PySpark. \n",
    "\n",
    "Then there's the overarching idea of the Data Science Pipeline: a concept in business that describes the general process for going from raw data to something that creates value for the business, as this [example](https://www.ibm.com/developerworks/library/ba-intro-data-science-1/index.html) from IBM illustrates.\n",
    "\n",
    "Then, there is the scikit-learn Pipeline modeule (term?). This can be described as a simple way, using scikit-learn, to work through the beginning/middle steps of the Data Science Pipeline. **In scikit-learn, a Pipeline is a string of transforms with a final estimator.** All of these steps in the pipeline (transformers and estimators) can be user-defined or from scikit-learn.\n",
    "\n",
    "**You can make user-defined pipeline steps by inheriting from the TransformerMixin and BaseEstimator parent classes**. If you inherit from these and write your transformer or estimator properly, they will work together in the pipeline seamlessly!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Scikit-learn pipelines to the rescue\n",
    "-------------\n",
    "\n",
    "Fortunately scikit-learn provides a set of helpful functions to deal with pipelines.\n",
    "2 of them are the most important:\n",
    "\n",
    "1. `sklearn.pipeline.make_pipeline`\n",
    "\n",
    "    In our previous example we could define our transformer like this\n",
    "    \n",
    "```python\n",
    "adder_normalizer = make_pipeline(\n",
    "    AdderTransformer(add=10),\n",
    "    MeanNormalizer()\n",
    ")\n",
    "```\n",
    "\n",
    "2. `sklearn.pipeline.make_union`\n",
    "\n",
    "    Creates a union of transformers\n",
    "    \n",
    "    ```\n",
    "    \n",
    "             transformer 1\n",
    "           /               \\\n",
    "          /                 \\\n",
    "    input                     output\n",
    "          \\                 /    \n",
    "           \\               /\n",
    "             transformer 2\n",
    "             \n",
    "    ```\n",
    "             \n",
    "    It is useful when the dataset consists of several types of data that one must \n",
    "    deal with separately.\n",
    "\n",
    "\n",
    "Alternative way to define pipelines\n",
    "--------------\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "adder_normalizer = Pipeline([\n",
    "    ('adder', AdderTransformer(add=10)),\n",
    "    ('normalizer', MeanNormalizer()),    \n",
    "])\n",
    "\n",
    "print(adder_normalizer)\n",
    "\n",
    ">> Pipeline(steps=[('adder', <__main__.AdderTransformer object at 0x7f9387473750>), ('normalizer', <__main__.MeanNormalizer object at 0x7f9387137e50>)])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples with real data: Predicting Absenteeism at Work\n",
    "Here, we will take a real data set, and follow first the exploratory phase, then make it into a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                   int64\n",
      "Reason for absence                  object\n",
      "Month of absence                     int64\n",
      "Day of the week                     object\n",
      "Transportation expense               int64\n",
      "Distance from Residence to Work      int64\n",
      "Service time                         int64\n",
      "Age                                  int64\n",
      "Work load Average/day              float64\n",
      "Hit target                           int64\n",
      "Disciplinary failure                 int64\n",
      "Education                           object\n",
      "Number of Children                   int64\n",
      "Social drinker                       int64\n",
      "Social smoker                        int64\n",
      "Pet                                  int64\n",
      "Weight                               int64\n",
      "Height                               int64\n",
      "Body mass index                      int64\n",
      "Absenteeism time in hours            int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Summary Statistics for Target Variable \n",
      " count    740.000000\n",
      "mean       6.924324\n",
      "std       13.330998\n",
      "min        0.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        8.000000\n",
      "max      120.000000\n",
      "Name: Absenteeism time in hours, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absenteeism time in hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Patient follow-up</td>\n",
       "      <td>7</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>No reason given</td>\n",
       "      <td>7</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>High school</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Blood donation</td>\n",
       "      <td>7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Diseases of the eye and adnexa</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Blood donation</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID              Reason for absence  Month of absence Day of the week  \\\n",
       "0  11               Patient follow-up                 7         Tuesday   \n",
       "1  36                 No reason given                 7         Tuesday   \n",
       "2   3                  Blood donation                 7       Wednesday   \n",
       "3   7  Diseases of the eye and adnexa                 7        Thursday   \n",
       "4  11                  Blood donation                 7        Thursday   \n",
       "\n",
       "   Transportation expense  Distance from Residence to Work  Service time  Age  \\\n",
       "0                     289                               36            13   33   \n",
       "1                     118                               13            18   50   \n",
       "2                     179                               51            18   38   \n",
       "3                     279                                5            14   39   \n",
       "4                     289                               36            13   33   \n",
       "\n",
       "   Work load Average/day   Hit target  Disciplinary failure    Education  \\\n",
       "0                 239.554          97                     0  High school   \n",
       "1                 239.554          97                     1  High school   \n",
       "2                 239.554          97                     0  High school   \n",
       "3                 239.554          97                     0  High school   \n",
       "4                 239.554          97                     0  High school   \n",
       "\n",
       "   Number of Children  Social drinker  Social smoker  Pet  Weight  Height  \\\n",
       "0                   2               1              0    1      90     172   \n",
       "1                   1               1              0    0      98     178   \n",
       "2                   0               1              0    0      89     170   \n",
       "3                   2               1              1    0      68     168   \n",
       "4                   2               1              0    1      90     172   \n",
       "\n",
       "   Body mass index  Absenteeism time in hours  \n",
       "0               30                          4  \n",
       "1               31                          0  \n",
       "2               31                          2  \n",
       "3               24                          4  \n",
       "4               30                          2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data/data.csv')\n",
    "print(data.dtypes)\n",
    "print('\\n')\n",
    "print('Summary Statistics for Target Variable \\n', data['Absenteeism time in hours'].describe())\n",
    "# we have a mix of categorical, numeric, and string data.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by writing some initial tests to check our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that we don't have any null values\n",
    "assert data.isnull().any().any() == False\n",
    "\n",
    "# test passes. No missing values exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we get an initial idea of the shape and form of our data?\n",
    "\n",
    "We can start by phrasing a few questions, and working to answer them.\n",
    "\n",
    "#### 1. What is the average amount of time for which employees are sick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.924324324324324"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Absenteeism time in hours'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is the average age of our employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.45"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. What are the most common reason that employees are absent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reason for absence\n",
       "Blood donation                                                  149\n",
       "Dental Consultation                                             112\n",
       "Physiotherapy                                                    69\n",
       "Diseases of the muskuloskeletal system and connective tissue     55\n",
       "No reason given                                                  43\n",
       "Name: Reason for absence, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['Reason for absence'])['Reason for absence'].count().sort_values(ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Write your own question and answer it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have a rough idea of the data, we can start preparing it for modeling.\n",
    "At the very least, we need to:\n",
    "1. Separate the target from the features\n",
    "2. Split the data into test and train \n",
    "3. Encode the categorical features (also means separating them from the numeric features)\n",
    "4. Scale the numeric features\n",
    "5. Choose and apply a final estimator\n",
    "6. Calculate the score of the estimator\n",
    "\n",
    "**Which of these steps can we build into a pipeline?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-pipeline steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data['Absenteeism time in hours']\n",
    "features = data.drop('Absenteeism time in hours', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Steps: \n",
    "### Step 1: Building the Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the numeric columns from the categorical ones:\n",
    "Start with a test! What does the outcome look like?\n",
    "We can start with the assert statement, and work backwards to developing a full test. \n",
    "\n",
    "\n",
    "```python\n",
    "# checking that when we fit & transform with the transformer, we only have numeric columns.\n",
    "for column in processed_df:\n",
    "    assert is_numeric_dtype(df[column])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also start by defining what columns are categorical and what columns are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Reason for absence', 'Month of absence', 'Day of the week',\n",
      "       'Transportation expense', 'Distance from Residence to Work',\n",
      "       'Service time', 'Age', 'Work load Average/day ', 'Hit target',\n",
      "       'Disciplinary failure', 'Education', 'Number of Children',\n",
      "       'Social drinker', 'Social smoker', 'Pet', 'Weight', 'Height',\n",
      "       'Body mass index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Some of the \"numeric\" columns are more categorical in nature (ex: month of absence, ID). However becasue these are already represented with a number, they should be grouped with the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_columns = ['ID',\n",
    "                   'Month of absence',\n",
    "                   'Transportation Expense',\n",
    "                   'Distance from Residence to Work',\n",
    "                   'Service time',\n",
    "                   'Day of Week',\n",
    "                   'Age',\n",
    "                   'Work load Average/day ',\n",
    "                   'Hit target',\n",
    "                   'Disciplinary failure',\n",
    "                   'Number of Children',\n",
    "                   'Social drinker', \n",
    "                   'Social smoker', \n",
    "                   'Pet', \n",
    "                   'Weight', \n",
    "                   'Height',\n",
    "                   'Body mass index'\n",
    "                  ]\n",
    "\n",
    "categoric_columns = ['Reason for absence',\n",
    "                     'Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipytest.magics\n",
    "import pytest\n",
    "# set the file name (required)\n",
    "__file__ = '1.3 Pipelines .ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test SHOULD fail! We haven't written the column selector yet!<br>\n",
    "Our goal is to make the test pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /Users/rachelberryman/Documents/DSR_Model_Pipelines_Course, inifile:\n",
      "collected 1 item\n",
      "\n",
      "1.3 Pipelines .py F\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "_____________________________ test_ColumnSelector ______________________________\n",
      "\n",
      "    def test_ColumnSelector():\n",
      "        # Here, showing a test case for both categoric and numeric datatypes.\n",
      ">       for column in numeric_df:\n",
      "E       NameError: name 'numeric_df' is not defined\n",
      "\n",
      "<ipython-input-12-005d543dfbd4>:4: NameError\n",
      "=========================== 1 failed in 0.18 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest \n",
    "\n",
    "def test_ColumnSelector():\n",
    "    # Here, showing a test case for both categoric and numeric datatypes.\n",
    "    for column in numeric_df:\n",
    "        assert is_numeric_dtype(numeric_df[column]) == True\n",
    "    \n",
    "    for column in categoric_df:\n",
    "        assert is_numeric_dtype(categoric_df[column]) == False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return x.loc[:,self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if we can make our test pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_selector = ColumnSelector(numeric_columns)\n",
    "numeric_df = numeric_selector.fit_transform(x_train)\n",
    "\n",
    "categoric_selector = ColumnSelector(categoric_columns)\n",
    "categoric_df = categoric_selector.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reason for absence    object\n",
       "Education             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoric_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /Users/rachelberryman/Documents/DSR_Model_Pipelines_Course, inifile:\n",
      "collected 1 item\n",
      "\n",
      "1.3 Pipelines .py .\n",
      "\n",
      "=========================== 1 passed in 0.02 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest \n",
    "\n",
    "def test_ColumnSelector():\n",
    "    # Here, showing a test case for both categoric and numeric datatypes.\n",
    "    for column in numeric_df:\n",
    "        assert is_numeric_dtype(numeric_df[column]) == True\n",
    "    \n",
    "    for column in categoric_df:\n",
    "        assert is_numeric_dtype(categoric_df[column]) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can write more tests for the additional transformers we want to add into our pipeline.\n",
    "<del>`class CategoricFeatureEncoder(BaseEstimator, TransformerMixin):`</del>\n",
    "\n",
    "we don't need to write our own class for this. Scikit-learn already has many built in. **When possible, don't reinvent the wheel. Use the transformers that are already there for you!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 2 different encoders in our pipeline. The feature \"Reason for absence\" has 28 distinct categories. This is too many to one-hot encode and would add too many features when our dataset only has 740 records.\n",
    "\n",
    "We can still write some tests to see that they're working correctly. We'll start by using our ColumnSelector transformer (from our tests above) to separate out the 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encode_columns = categoric_df['Reason for absence']\n",
    "one_hot_encode_columns = categoric_df['Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /Users/rachelberryman/Documents/DSR_Model_Pipelines_Course, inifile:\n",
      "collected 2 items\n",
      "\n",
      "1.3 Pipelines .py ..\n",
      "\n",
      "=========================== 2 passed in 0.03 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest \n",
    "\n",
    "def test_LabelEncoder():\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_df = encoder.fit_transform(label_encode_columns)\n",
    "    \n",
    "    # check for data leakage\n",
    "    assert encoded_df.shape[0] == categoric_df.shape[0]\n",
    "    \n",
    "    # check that all values have been converted into integers\n",
    "    assert encoded_df.dtype == 'int64'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Write a test for the One-Hot Encoder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double click to see the solution**\n",
    "\n",
    "<div class='spoiler'>\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Why are we not using the One-Hot Encoder from Scikit-Learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /anaconda3/lib/python3.6/site-packages (1.2.8)\n",
      "Requirement already satisfied: scikit-learn>=0.15.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (0.19.1)\n",
      "Requirement already satisfied: pandas>=0.15.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (0.22.0)\n",
      "Requirement already satisfied: scipy>=0.9 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (1.0.1)\n",
      "Requirement already satisfied: statsmodels<=0.8.0,>=0.6.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (0.8.0)\n",
      "Requirement already satisfied: patsy>=0.4.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (1.14.2)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.6/site-packages (from pandas>=0.15.0->category_encoders) (2017.2)\n",
      "Requirement already satisfied: python-dateutil>=2 in /Users/rachelberryman/.local/lib/python3.6/site-packages (from pandas>=0.15.0->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from patsy>=0.4.0->category_encoders) (1.11.0)\n",
      "\u001b[31mboto3 1.5.33 has requirement botocore<1.9.0,>=1.8.47, but you'll have botocore 1.10.19 which is incompatible.\u001b[0m\n",
      "\u001b[31mbacnet-controller 0.0.1 has requirement boto3==1.5.12, but you'll have boto3 1.5.33 which is incompatible.\u001b[0m\n",
      "\u001b[31mbacnet-controller 0.0.1 has requirement pytz==2018.3, but you'll have pytz 2017.2 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.0, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.one_hot import OneHotEncoder\n",
    "one_hot = OneHotEncoder()\n",
    "one_hot_encoded_df = one_hot.fit_transform(one_hot_encode_columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /Users/rachelberryman/Documents/DSR_Model_Pipelines_Course, inifile:\n",
      "collected 1 item\n",
      "\n",
      "1.3 Pipelines .py .\n",
      "\n",
      "=========================== 1 passed in 0.05 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_OneHotEncoder():\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    one_hot_encoded_df = one_hot.fit_transform(one_hot_encode_columns.values)\n",
    "    \n",
    "    # check for data leakage\n",
    "    assert one_hot_encoded_df.shape[0] == categoric_df.shape[0]\n",
    "    \n",
    "    # check that all values have been converted into integers\n",
    "    assert one_hot_encoded_df.dtypes.all() == 'int64'\n",
    "    \n",
    "    # check that only 0s and 1s exist in the new matrix\n",
    "    assert ((one_hot_encoded_df.values ==0) | (one_hot_encoded_df.values ==1)).all()\n",
    "    \n",
    "    # check that a dummy column has been made for each potential category \n",
    "    assert one_hot_encoded_df.shape[1] == len(set(one_hot_encode_columns)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
