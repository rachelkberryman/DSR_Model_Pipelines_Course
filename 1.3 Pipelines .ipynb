{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3: Pipelines\n",
    "================\n",
    "### Stringing it All Together\n",
    "_____________________\n",
    "\n",
    "**Pipelines** has a few different meanings in Data Science.\n",
    "\n",
    "This creates some ambiguity as the terms are often used interchangably.\n",
    "\n",
    "There's [Spark Pipelines](https://spark.apache.org/docs/2.2.0/ml-pipeline.html), used to process data in PySpark. \n",
    "\n",
    "Then there's the overarching idea of the Data Science Pipeline: a concept in business that describes the general process for going from raw data to something that creates value for the business, as this [example](https://www.ibm.com/developerworks/library/ba-intro-data-science-1/index.html) from IBM illustrates.\n",
    "\n",
    "Then, there is the scikit-learn Pipeline modeule (term?). This can be described as a simple way, using scikit-learn, to work through the beginning/middle steps of the Data Science Pipeline. **In scikit-learn, a Pipeline is a string of transforms with a final estimator.** All of these steps in the pipeline (transformers and estimators) can be user-defined or from scikit-learn.\n",
    "\n",
    "**You can make user-defined pipeline steps by inheriting from the TransformerMixin and BaseEstimator parent classes**. If you inherit from these and write your transformer or estimator properly, they will work together in the pipeline seamlessly!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Scikit-learn pipelines to the rescue\n",
    "-------------\n",
    "\n",
    "Fortunately scikit-learn provides a set of helpful functions to deal with pipelines.\n",
    "2 of them are the most important:\n",
    "\n",
    "1. `sklearn.pipeline.make_pipeline`\n",
    "\n",
    "    In our previous example we could define our transformer like this\n",
    "    \n",
    "```python\n",
    "adder_normalizer = make_pipeline(\n",
    "    AdderTransformer(add=10),\n",
    "    MeanNormalizer()\n",
    ")\n",
    "```\n",
    "Calling `fit` on the pipeline is the same as calling fit on each estimator in turn, transform the input and pass it on to the next step. The pipeline has all the methods that the last estimator in the pipeline has, i.e. if the last estimator is a classifier, the Pipeline can be used as a classifier. If the last estimator is a transformer, again, so is the pipeline.\n",
    "\n",
    "2. `sklearn.pipeline.make_union`\n",
    "\n",
    "    Creates a union of transformers\n",
    "    \n",
    "    ```\n",
    "    \n",
    "             transformer 1\n",
    "           /               \\\n",
    "          /                 \\\n",
    "    input                     output\n",
    "          \\                 /    \n",
    "           \\               /\n",
    "             transformer 2\n",
    "             \n",
    "    ```\n",
    "             \n",
    "    It is useful when the dataset consists of several types of data that one must \n",
    "    deal with separately.\n",
    "\n",
    "\n",
    "Alternative way to define pipelines\n",
    "--------------\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "adder_normalizer = Pipeline([\n",
    "    ('adder', AdderTransformer(add=10)),\n",
    "    ('normalizer', MeanNormalizer()),    \n",
    "])\n",
    "\n",
    "print(adder_normalizer)\n",
    "\n",
    ">> Pipeline(steps=[('adder', <__main__.AdderTransformer object at 0x7f9387473750>), ('normalizer', <__main__.MeanNormalizer object at 0x7f9387137e50>)])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples with real data: Predicting Absenteeism at Work\n",
    "Here, we will take a real data set, and follow first the exploratory phase, then make it into a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                           int64\n",
      "ID                                   int64\n",
      "Reason for absence                  object\n",
      "Month of absence                     int64\n",
      "Day of the week                     object\n",
      "Distance from Residence to Work      int64\n",
      "Service time                         int64\n",
      "Age                                  int64\n",
      "Work load Average/day              float64\n",
      "Hit target                           int64\n",
      "Disciplinary failure                 int64\n",
      "Education                           object\n",
      "Number of Children                   int64\n",
      "Social drinker                       int64\n",
      "Social smoker                        int64\n",
      "Pet                                  int64\n",
      "Weight                               int64\n",
      "Height                               int64\n",
      "Body mass index                      int64\n",
      "Absenteeism time in hours            int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Summary Statistics for Target Variable \n",
      " count    740.000000\n",
      "mean       6.924324\n",
      "std       13.330998\n",
      "min        0.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        8.000000\n",
      "max      120.000000\n",
      "Name: Absenteeism time in hours, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absenteeism time in hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Patient follow-up</td>\n",
       "      <td>7</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>No reason given</td>\n",
       "      <td>7</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>High school</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Blood donation</td>\n",
       "      <td>7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>Diseases of the eye and adnexa</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Blood donation</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID              Reason for absence  Month of absence  \\\n",
       "0           0  11               Patient follow-up                 7   \n",
       "1           1  36                 No reason given                 7   \n",
       "2           2   3                  Blood donation                 7   \n",
       "3           3   7  Diseases of the eye and adnexa                 7   \n",
       "4           4  11                  Blood donation                 7   \n",
       "\n",
       "  Day of the week  Distance from Residence to Work  Service time  Age  \\\n",
       "0         Tuesday                               36            13   33   \n",
       "1         Tuesday                               13            18   50   \n",
       "2       Wednesday                               51            18   38   \n",
       "3        Thursday                                5            14   39   \n",
       "4        Thursday                               36            13   33   \n",
       "\n",
       "   Work load Average/day   Hit target  Disciplinary failure    Education  \\\n",
       "0                 239.554          97                     0  High school   \n",
       "1                 239.554          97                     1  High school   \n",
       "2                 239.554          97                     0  High school   \n",
       "3                 239.554          97                     0  High school   \n",
       "4                 239.554          97                     0  High school   \n",
       "\n",
       "   Number of Children  Social drinker  Social smoker  Pet  Weight  Height  \\\n",
       "0                   2               1              0    1      90     172   \n",
       "1                   1               1              0    0      98     178   \n",
       "2                   0               1              0    0      89     170   \n",
       "3                   2               1              1    0      68     168   \n",
       "4                   2               1              0    1      90     172   \n",
       "\n",
       "   Body mass index  Absenteeism time in hours  \n",
       "0               30                          4  \n",
       "1               31                          0  \n",
       "2               31                          2  \n",
       "3               24                          4  \n",
       "4               30                          2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data/data.csv')\n",
    "print(data.dtypes)\n",
    "print('\\n')\n",
    "print('Summary Statistics for Target Variable \\n', data['Absenteeism time in hours'].describe())\n",
    "# we have a mix of categorical, numeric, and string data.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by writing some initial tests to check our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that we don't have any null values\n",
    "assert data.isnull().any().any() == False\n",
    "\n",
    "# test passes. No missing values exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we get an initial idea of the shape and form of our data?\n",
    "\n",
    "We can start by phrasing a few questions, and working to answer them.\n",
    "\n",
    "#### 1. What is the average amount of time for which employees are sick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.924324324324324"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Absenteeism time in hours'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is the average age of our employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.45"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. What are the most common reason that employees are absent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reason for absence\n",
       "Blood donation                                                  149\n",
       "Dental Consultation                                             112\n",
       "Physiotherapy                                                    69\n",
       "Diseases of the muskuloskeletal system and connective tissue     55\n",
       "No reason given                                                  43\n",
       "Name: Reason for absence, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['Reason for absence'])['Reason for absence'].count().sort_values(ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Write your own question and answer it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have a rough idea of the data, we can start preparing it for modeling.\n",
    "At the very least, we need to:\n",
    "1. Separate the target from the features\n",
    "2. Split the data into test and train \n",
    "3. Encode the categorical features (also means separating them from the numeric features)\n",
    "4. Scale the numeric features\n",
    "5. Choose and apply a final estimator\n",
    "6. Calculate the score of the estimator\n",
    "\n",
    "**Which of these steps can we build into a pipeline?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-pipeline steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data['Absenteeism time in hours']\n",
    "features = data.drop('Absenteeism time in hours', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Steps: \n",
    "### Step 1: Building the Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the numeric columns from the categorical ones:\n",
    "Start with a test! What does the outcome look like?\n",
    "We can start with the assert statement, and work backwards to developing a full test. \n",
    "\n",
    "\n",
    "```python\n",
    "# checking that when we fit & transform with the transformer, we only have numeric columns.\n",
    "for column in processed_df:\n",
    "    assert is_numeric_dtype(df[column])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also start by defining what columns are categorical and what columns are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'ID', 'Reason for absence', 'Month of absence',\n",
      "       'Day of the week', 'Distance from Residence to Work', 'Service time',\n",
      "       'Age', 'Work load Average/day ', 'Hit target', 'Disciplinary failure',\n",
      "       'Education', 'Number of Children', 'Social drinker', 'Social smoker',\n",
      "       'Pet', 'Weight', 'Height', 'Body mass index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Some of the \"numeric\" columns are more categorical in nature (ex: month of absence, ID). However becasue these are already represented with a number, they should be grouped with the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_columns = ['Distance from Residence to Work',\n",
    "                   'Service time',\n",
    "                   'Age',\n",
    "                   'Work load Average/day ',\n",
    "                   'Number of Children',\n",
    "                   'Weight', \n",
    "                   'Height',\n",
    "                   'Body mass index']\n",
    "\n",
    "binary_columns = ['ID',\n",
    "                  'Month of absence',\n",
    "                  'Day of Week',\n",
    "                  'Disciplinary failure',\n",
    "                  'Hit target',\n",
    "                  'Social drinker', \n",
    "                  'Social smoker', \n",
    "                  'Pet']\n",
    "\n",
    "categoric_columns = ['Reason for absence',\n",
    "                     'Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipytest.magics\n",
    "import pytest\n",
    "# set the file name (required)\n",
    "__file__ = '1.3 Pipelines .ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test SHOULD fail! We haven't written the column selector yet!<br>\n",
    "Our goal is to make the test pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /Users/rachelberryman/Documents/DSR_Model_Pipelines_Course, inifile:\n",
      "collected 2 items\n",
      "\n",
      "1.3 Pipelines .py ..\n",
      "\n",
      "=========================== 2 passed in 0.06 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest \n",
    "\n",
    "def test_ColumnSelector():\n",
    "    # Here, showing a test case for both categoric and numeric datatypes.\n",
    "    for column in numeric_df:\n",
    "        assert is_numeric_dtype(numeric_df[column]) == True\n",
    "    \n",
    "    for column in categoric_df:\n",
    "        assert is_numeric_dtype(categoric_df[column]) == False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return x.loc[:,self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if we can make our test pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_selector = ColumnSelector(numeric_columns)\n",
    "numeric_df = numeric_selector.fit_transform(x_train)\n",
    "#numeric_df.dropna(inplace=True)\n",
    "\n",
    "categoric_selector = ColumnSelector(categoric_columns)\n",
    "categoric_df = categoric_selector.fit_transform(x_train)\n",
    "\n",
    "binary_selector = ColumnSelector(binary_columns)\n",
    "binary_df = binary_selector.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reason for absence    object\n",
       "Education             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoric_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /Users/rachelberryman/Documents/DSR_Model_Pipelines_Course, inifile:\n",
      "collected 2 items\n",
      "\n",
      "1.3 Pipelines .py ..\n",
      "\n",
      "=========================== 2 passed in 0.05 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest \n",
    "\n",
    "def test_ColumnSelector():\n",
    "    # Here, showing a test case for both categoric and numeric datatypes.\n",
    "    for column in numeric_df:\n",
    "        assert is_numeric_dtype(numeric_df[column]) == True\n",
    "    \n",
    "    for column in categoric_df:\n",
    "        assert is_numeric_dtype(categoric_df[column]) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can write more tests for the additional transformers we want to add into our pipeline.\n",
    "<del>`class CategoricFeatureEncoder(BaseEstimator, TransformerMixin):`</del>\n",
    "\n",
    "we don't need to write our own class for this. Scikit-learn already has many built in. **When possible, don't reinvent the wheel. Use the transformers that are already there for you!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 2 different encoders in our pipeline. The feature \"Reason for absence\" has 28 distinct categories. This is too many to one-hot encode and would add too many features when our dataset only has 740 records.\n",
    "\n",
    "We can still write some tests to see that they're working correctly. We'll start by using our ColumnSelector transformer (from our tests above) to separate out the 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encode_columns = categoric_df['Reason for absence']\n",
    "one_hot_encode_columns = categoric_df['Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /Users/rachelberryman/Documents/DSR_Model_Pipelines_Course, inifile:\n",
      "collected 3 items\n",
      "\n",
      "1.3 Pipelines .py ...\n",
      "\n",
      "=========================== 3 passed in 0.06 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest \n",
    "\n",
    "def test_LabelEncoder():\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_df = encoder.fit_transform(label_encode_columns)\n",
    "    \n",
    "    # check for data leakage\n",
    "    assert encoded_df.shape[0] == categoric_df.shape[0]\n",
    "    \n",
    "    # check that all values have been converted into integers\n",
    "    assert encoded_df.dtype == 'int64'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Write a test for the One-Hot Encoder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double click to see the solution**\n",
    "\n",
    "<div class='spoiler'>\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Why are we not using the One-Hot Encoder from Scikit-Learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /anaconda3/lib/python3.6/site-packages (1.2.8)\n",
      "Requirement already satisfied: patsy>=0.4.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (1.14.2)\n",
      "Requirement already satisfied: scikit-learn>=0.15.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (0.19.1)\n",
      "Requirement already satisfied: scipy>=0.9 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (1.0.1)\n",
      "Requirement already satisfied: pandas>=0.15.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (0.22.0)\n",
      "Requirement already satisfied: statsmodels<=0.8.0,>=0.6.0 in /anaconda3/lib/python3.6/site-packages (from category_encoders) (0.8.0)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from patsy>=0.4.0->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2 in /Users/rachelberryman/.local/lib/python3.6/site-packages (from pandas>=0.15.0->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.6/site-packages (from pandas>=0.15.0->category_encoders) (2017.2)\n",
      "\u001b[31mboto3 1.5.33 has requirement botocore<1.9.0,>=1.8.47, but you'll have botocore 1.10.19 which is incompatible.\u001b[0m\n",
      "\u001b[31mbacnet-controller 0.0.1 has requirement boto3==1.5.12, but you'll have boto3 1.5.33 which is incompatible.\u001b[0m\n",
      "\u001b[31mbacnet-controller 0.0.1 has requirement pytz==2018.3, but you'll have pytz 2017.2 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.one_hot import OneHotEncoder\n",
    "one_hot = OneHotEncoder()\n",
    "one_hot_encoded_df = one_hot.fit_transform(one_hot_encode_columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /Users/rachelberryman/Documents/DSR_Model_Pipelines_Course, inifile:\n",
      "collected 1 item\n",
      "\n",
      "1.3 Pipelines .py .\n",
      "\n",
      "=========================== 1 passed in 0.04 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_OneHotEncoder():\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    one_hot_encoded_df = one_hot.fit_transform(one_hot_encode_columns.values)\n",
    "    \n",
    "    # check for data leakage\n",
    "    assert one_hot_encoded_df.shape[0] == categoric_df.shape[0]\n",
    "    \n",
    "    # check that all values have been converted into integers\n",
    "    assert one_hot_encoded_df.dtypes.all() == 'int64'\n",
    "    \n",
    "    # check that only 0s and 1s exist in the new matrix\n",
    "    assert ((one_hot_encoded_df.values ==0) | (one_hot_encoded_df.values ==1)).all()\n",
    "    \n",
    "    # check that a dummy column has been made for each potential category \n",
    "    assert one_hot_encoded_df.shape[1] == len(set(one_hot_encode_columns)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Numeric Data: Using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>264.249</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>169</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>237.656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>172</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>205.917</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>244.387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>237.656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>178</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distance from Residence to Work  Service time  Age  \\\n",
       "599                               26             9   28   \n",
       "674                               11            14   37   \n",
       "24                                36            13   33   \n",
       "394                               51            18   38   \n",
       "698                               16             8   32   \n",
       "\n",
       "     Work load Average/day   Disciplinary failure  Number of Children  Weight  \\\n",
       "599                 264.249                     0                   1      69   \n",
       "674                 237.656                     0                   1      88   \n",
       "24                  205.917                     0                   2      90   \n",
       "394                 244.387                     0                   0      89   \n",
       "698                 237.656                     0                   0      75   \n",
       "\n",
       "     Height  Body mass index  \n",
       "599     169               24  \n",
       "674     172               29  \n",
       "24      172               30  \n",
       "394     170               31  \n",
       "698     178               25  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_numeric = scaler.fit_transform(numeric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, to Pipelines!\n",
    "We've tested our transformers and are sure they are working. What we need to do now is string them together in a pipeline, and re-combine the various features.\n",
    "\n",
    "Without a pipeline, we would have had to do this by merging all or our new features. \n",
    "This is difficult, since after scaling, the numeric features are a matrix. The binary and categoric features are still dataframes.\n",
    "A pipeline, combined with another scikit-learn tool `make_union`, does all of this work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "\n",
    "processing_pipeline = make_pipeline(\n",
    "    # First, we select and 'hold out' the binary variables, as we wont do any further work to them.\n",
    "    ColumnSelector(binary_columns),\n",
    "    \n",
    "    # process the numeric and \n",
    "    make_union(\n",
    "        # Pipeline for numeric features\n",
    "        make_pipeline(\n",
    "            ColumnSelector([\"Open\", \"Promo\", \"SchoolHoliday\", \"CompetitionDistance\", \n",
    "                            \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \n",
    "                            \"Promo2\", \"Promo2SinceWeek\", \"Promo2SinceYear\"]),\n",
    "        ),\n",
    "        # Pipeline for label encoded features\n",
    "        make_pipeline(\n",
    "            PandasSelector([\"Date\"]),\n",
    "            ExtractDateAttributes()\n",
    "        ),\n",
    "        \n",
    "        # Pipeline for one-hot-encoded features\n",
    "        make_pipeline(\n",
    "            PandasSelector([\"StoreType\", \"Assortment\"]),\n",
    "            PandasToDict(),\n",
    "            DictVectorizer(sparse=False)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, choosing the final estimator.\n",
    "We can use our estiamtor tests we wrote in the beginning of class, when we learned about tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting random seed for reproducability. \n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
